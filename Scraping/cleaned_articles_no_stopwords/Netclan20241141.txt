Title: Immigration Datawarehouse & AI-based recommendations Client BackgroundClient: leading business school worldwideIndustry Type: R&DServices: R&D, InnovationOrganization Size: 100+Project ObjectiveObjective project research collect news article data sourcing Canada, based keyword. Project DescriptionThere 3 phases project. Phase 1– Data collection selectionData related coming (new comers)Data related coming (new comers) policy comersi.e. CanadaData News, press, tanks, government policy documents, research institutions releasing news press aboutThe news source limited onlyTime span- 2005 2021Output- Excel URLs documents source type, keywords, article posted.Phase 2– Documents text data extraction Develop tool collect extract data URL.Clean save texts text documentsPhase 3– Textual AnalysisSentiment AnalysisAnalysis readabilityTopic modelling SolutionWe provide completed Phase 1 excel sheet ongoing Phase 2. work Phase 3 started complete Project way.Project DeliverablesThere file excel sheet file summary dataset folders text files data Phase 2.Tools usedPython, PyCharm, Jupyter Notebook, Microsoft Excel, Google Chrome complete phases projectLanguage/techniques usedPython programming language Web Scraping, Automation, Data Engineering project.Models usedSDLC process software project, software organization. consists detailed plan describing develop, maintain, replace alter enhance specific software. life cycle defines methodology improving quality software development process.We Iterative Waterfall SDLC Model follow development software phases feedback step development project track occurring step.Figure 1 SDLC Iterative Waterfall ModelSkills usedData scraping, cleaning, pre-processing creating data pipelines project.Databases usedWe traditional storing data i.e file systems. technical Challenges Faced Project ExecutionThere lot challenges faced project execution. internet, raw data us. So, search important data specifically related only, lot keywords challenging part us.Then, manage task automating upto extent only, required find dates articles, news, tanks, documents etc, challenging part.While working Phase 2, scrape data URLs, sometimes, news articles removed website, earlier datasets problems extracting data.Then cleaning webpages challenge us, project research, data important us. So, difficult data website require important.How Technical Challenges SolvedBelow points solve technical challenges-We sitemaps websites find articles require keywords, research find URL solve purpose. checking results automation tools, created, done.To find dates articles, wrote multiple regular expressions, find match dates need, checking that.To scrape removed webpages, WayBack machine google archives, stores deleted webpages.To clean data, filtered HTML tags, classes, ids regex, research.Project Snapshots Previous articleLipsync Automation Celebrities InfluencersNext articleA Leading Firm USA, SEO Website Optimization Ajay Bidyarthy RELATED ARTICLESMORE AUTHOR Integrating Machine Learning Code Kubeflow Pipeline – Kuberflow MLOps KubernetesFacial Recognition Attendance SystemFace Recognition DeepFace